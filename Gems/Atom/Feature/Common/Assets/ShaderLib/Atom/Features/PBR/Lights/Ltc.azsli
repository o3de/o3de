/* begin-license-attribution:

This code is based in part on third-party work(s), see below for applicable
terms and attribution information.  Modifications copyright (c) Amazon.com, 
Inc. or its affiliates or licensors.

begin-original-license-text:

Copyright (c) 2017, Eric Heitz, Jonathan Dupuy, Stephen Hill and David Neubelt.
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

* If you use (or adapt) the source code in your own work, please include a 
reference to the paper:

Real-Time Polygonal-Light Shading with Linearly Transformed Cosines.
Eric Heitz, Jonathan Dupuy, Stephen Hill and David Neubelt.
ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH 2016) 35(4), 2016.
Project page: https://eheitzresearch.wordpress.com/415-2/

* Redistributions of source code must retain the above copyright notice, this
list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice,
this list of conditions and the following disclaimer in the documentation
and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

end-license-attribution */

#pragma once

#include <Atom/Features/PBR/Lights/LightTypesCommon.azsli>

// Generates UV coords for LTC lookup table
float2 LtcCoords(float cosTheta, float roughness)
{
    float theta = acos(cosTheta);
    float2 coords = float2(roughness, theta / (0.5 * PI));

    const float LUT_SIZE = 32.0;
    // scale and bias coordinates, for correct filtered lookup
    coords = coords * ((LUT_SIZE - 1.0) / LUT_SIZE) + (0.5 / LUT_SIZE);

    return coords;
}

// Constructs an LTC matrix from the provided texture and coordinates.
float3x3 LtcMatrix(Texture2D<float4> ltcMatrix, float2 coord)
{
    float4 t = ltcMatrix.Sample(PassSrg::LinearSampler, coord);

    return float3x3(
        1.0, 0.0, t.w,
        0.0, t.z, 0.0,
        t.y, 0.0, t.x
    );
}

float3x3 BuildViewAlignedOrthonormalBasis(in float3 normal, in float3 dirToView)
{
    float3 tangent = normalize(dirToView - normal * dot(dirToView, normal));
    float3 bitangent = cross(normal, tangent);
    return float3x3(tangent, bitangent, normal);
}

// Cosine integration of edge in a hemisphere. v1 and v2 should be normalized vertices above the
// xy plane in positive z space.
float IntegrateEdge(float3 v1, float3 v2)
{
    // This alternate version may work better for platforms where acos() precision is low.
    /*
    float x = dot(v1, v2);
    float y = abs(x);

    float a = 5.42031 + (3.12829 + 0.0902326 * y) * y;
    float b = 3.45068 + (4.18814 + y) * y;
    float theta_sinTheta = a / b;

    if (x < 0.0)
    {
        theta_sinTheta = PI * rsqrt(saturate(1.0 - x * x)) - theta_sinTheta;
    }

    float3 u = cross(v1, v2);
    return theta_sinTheta * u.z;
    */

    float cosTheta = dot(v1, v2);
    float theta = acos(cosTheta);

    // calculate 1.0 / sin(theta)
    float invSinTheta = rsqrt(saturate(1.0 - cosTheta * cosTheta));

    return cross(v1, v2).z * ((theta > 0.001) ? theta * invSinTheta : 1.0);
}

// Cheaper version of above which is good enough for diffuse
float IntegrateEdgeDiffuse(float3 v1, float3 v2)
{
    float cosTheta = dot(v1, v2);
    float absCosTheta = abs(cosTheta);
    float theta_sinTheta = 1.5708 + (-0.879406 + 0.308609 * absCosTheta) * absCosTheta;
    if (cosTheta < 0.0)
    {
        theta_sinTheta = PI * rsqrt(1.0 - cosTheta * cosTheta) - theta_sinTheta;
    }
    return theta_sinTheta * cross(v1, v2).z;
}

// Returns the unnormalized z plane intersection point between pointAboveHorizon and pointBelowHorizon.
// Once normalized, this represents a direction vector on the z plane between the directions of
// pointAboveHorizon and pointBelowHorizon.
float3 ClipEdge(in float3 pointAboveHorizon, in float3 pointBelowHorizon)
{
    return pointAboveHorizon.z * pointBelowHorizon - pointBelowHorizon.z * pointAboveHorizon;
}

// Clips a quad to above the xy plane in positive z space. Returns number of points after
// clip in vertexCount. This could have a 5 point result if only one corner is clipped.
void ClipQuadToHorizon(inout float3 p[5], out int vertexCount)
{
    // detect clipping config
    int config = 0;
    config += step(0.0, p[0].z) * 1;
    config += step(0.0, p[1].z) * 2;
    config += step(0.0, p[2].z) * 4;
    config += step(0.0, p[3].z) * 8;

    vertexCount = 0;

    switch(config)
    {
    case 0: // clip all
        break;
    case 1: // clip p[1], p[2], p[3]
        vertexCount = 3;
        p[1] = ClipEdge(p[0], p[1]);
        p[2] = ClipEdge(p[0], p[3]);
        break;
    case 2: // clip p[0], p[2], p[3]
        vertexCount = 3;
        p[0] = ClipEdge(p[1], p[0]);
        p[2] = ClipEdge(p[1], p[2]);
        break;
    case 3: // clip p[2], p[3]
        vertexCount = 4;
        p[2] = ClipEdge(p[1], p[2]);
        p[3] = ClipEdge(p[0], p[3]);
        break;
    case 4: // clip p[0], p[1], p[3]
        vertexCount = 3;
        p[0] = ClipEdge(p[2], p[3]);
        p[1] = ClipEdge(p[2], p[1]);
        break;
    case 5: // clip p[1], p[3] - impossible (opposite corners)
        break;
    case 6: // clip p[0], p[3]
        vertexCount = 4;
        p[0] = ClipEdge(p[1], p[0]);
        p[3] = ClipEdge(p[2], p[3]);
        break;
    case 7: // clip p[3]
        vertexCount = 5;
        p[4] = ClipEdge(p[0], p[3]);
        p[3] = ClipEdge(p[2], p[3]);
        break;
    case 8: // clip p[0], p[1], p[2]
        vertexCount = 3;
        p[0] = ClipEdge(p[3], p[0]);
        p[1] = ClipEdge(p[3], p[2]);
        p[2] =  p[3];
        break;
    case 9: // clip p[1], p[2]
        vertexCount = 4;
        p[1] = ClipEdge(p[0], p[1]);
        p[2] = ClipEdge(p[3], p[2]);
        break;
    case 10: // clip p[0], p[2] - impossible (opposite corners)
        break;
    case 11: // clip p[2]
        vertexCount = 5;
        p[4] = p[3];
        p[3] = ClipEdge(p[3], p[2]);
        p[2] = ClipEdge(p[1], p[2]);
        break;
    case 12: // clip p[0], p[1]
        vertexCount = 4;
        p[1] = ClipEdge(p[2], p[1]);
        p[0] = ClipEdge(p[3], p[0]);
        break;
    case 13: // clip p[1]
        vertexCount = 5;
        p[4] = p[3];
        p[3] = p[2];
        p[2] = ClipEdge(p[2], p[1]);
        p[1] = ClipEdge(p[0], p[1]);
        break;
    case 14: // clip p[0]
        vertexCount = 5;
        p[4] = ClipEdge(p[3], p[0]);
        p[0] = ClipEdge(p[1], p[0]);
        break;
    case 15: // no clipping
        vertexCount = 4;
        break;
    }
}

// Applies the LTC matrix to the clipped points of a quad.
void ApplyLtcMatrixToQuad(in float3x3 ltcMat, inout float3 p[5], in int vertexCount)
{
    // Transform points into ltc space
    p[0] = mul(ltcMat, p[0]);
    p[1] = mul(ltcMat, p[1]);
    p[2] = mul(ltcMat, p[2]);

    if (vertexCount > 3)
    {
        p[3] = mul(ltcMat, p[3]);
    }
    if (vertexCount > 4)
    {
        p[4] = mul(ltcMat, p[4]);
    }
}

// Projects the clipped points of a quad onto the sphere.
void NormalizeQuadPoints(inout float3 p[5], in int vertexCount)
{
    // project quad points onto a sphere.
    p[0] = normalize(p[0]);
    p[1] = normalize(p[1]);
    p[2] = normalize(p[2]);

    if (vertexCount > 3)
    {
        p[3] = normalize(p[3]);
    }
    if (vertexCount > 4)
    {
        p[4] = normalize(p[4]);
    }
}

// Transforms the 4 points of a quad into the hemisphere of the normal
void TransformQuadToOrthonormalBasis(in float3 normal, in float3 dirToView, inout float3 p[4])
{
    float3x3 orthoNormalBasis = BuildViewAlignedOrthonormalBasis(normal, dirToView);

    // Transform points into orthonormal space
    p[0] = mul(orthoNormalBasis, p[0]);
    p[1] = mul(orthoNormalBasis, p[1]);
    p[2] = mul(orthoNormalBasis, p[2]);
    p[3] = mul(orthoNormalBasis, p[3]);
}

// Integrates the edges of a quad for lambertian diffuse contribution.
float IntegrateQuadDiffuse(in float3 v[5], in float vertexCount, in bool doubleSided)
{
    float sum = 0.0;

    NormalizeQuadPoints(v, vertexCount);

    // There must be at least 3 points so don't check for the first 2 edges.
    sum += IntegrateEdgeDiffuse(v[0], v[1]);
    sum += IntegrateEdgeDiffuse(v[1], v[2]);

    if (vertexCount > 3)
    {
        sum += IntegrateEdgeDiffuse(v[2], v[3]);
        if (vertexCount == 5)
        {
            sum += IntegrateEdgeDiffuse(v[3], v[4]);
        }
    }

    // Close the polygon
    sum += IntegrateEdgeDiffuse(v[vertexCount - 1], v[0]);

    // Note: negated due to winding order
    sum = doubleSided ? abs(sum) : max(0.0, -sum);

    return sum;
}

// Integrates the edges of a quad for specular contribution.
float IntegrateQuadSpecular(in float3 v[5], in float vertexCount, in bool doubleSided)
{
    float sum = 0.0;

    NormalizeQuadPoints(v, vertexCount);

    // There must be at least 3 points so don't check for the first 2 edges.
    sum += IntegrateEdge(v[0], v[1]);
    sum += IntegrateEdge(v[1], v[2]);

    if (vertexCount > 3)
    {
        sum += IntegrateEdge(v[2], v[3]);
        if (vertexCount == 5)
        {
            sum += IntegrateEdge(v[3], v[4]);
        }
    }

    // Close the polygon
    sum += IntegrateEdge(v[vertexCount - 1], v[0]);

    // Note: negated due to winding order
    sum = doubleSided ? abs(sum) : max(0.0, -sum);

    return sum;
}

// Evaluate linear transform cosine lighting for a 4 point quad.
//   normal - The surface normal
//   dirToView - Normalized direction from the surface to the view
//   ltcMat - The LTC matrix for specular, or identity for diffuse.
//   p[4] - The 4 light positions relative to the surface position.
//   doubleSided - If the quad emits light from both sides
//   diffuse - The output diffuse response for the quad light
//   specular - The output specular response for the quad light
void LtcQuadEvaluate(
    in float3 normal,
    in float3 dirToView,
    in float3x3 ltcMat,
    in float3 p[4],
    in bool doubleSided,
    out float diffuse,
    out float specular)
{
    // Transform the points of the light into the space of the normal's hemisphere.
    TransformQuadToOrthonormalBasis(normal, dirToView, p);

    // Initialize quad with dummy point at end in case one corner is clipped (resulting in 5 sided polygon)
    float3 v[5] = {p[0], p[1], p[2], p[3], float3(0.0, 0.0, 0.0)};

    // Clip the light polygon to the normal hemisphere. This is done before the LTC matrix is applied to prevent
    // parts of the light below the horizon from impacting the surface. The number of points remaining after
    // the clip is returned in vertexCount. It's possible for the vertexCount of the resulting clipped quad to be
    // 0 - all points clipped (no work to do, so return)
    // 3 - 3 points clipped, leaving only a triangular corner of the quad
    // 4 - 2 or 0 points clipped, leaving a quad
    // 5 - 1 point clipped leaving a pentagon.

    int vertexCount = 0;
    ClipQuadToHorizon(v, vertexCount);

    if (vertexCount == 0)
    {
        // Entire light is below the horizon.
        return;
    }

    // IntegrateQuadDiffuse is a cheap approximation compared to specular.
    diffuse = IntegrateQuadDiffuse(v, vertexCount, doubleSided);

    ApplyLtcMatrixToQuad(ltcMat, v, vertexCount);

    // IntegrateQuadSpecular uses more accurate integration to handle smooth surfaces correctly.
    specular = IntegrateQuadSpecular(v, vertexCount, doubleSided);
}

// Checks an edge against the horizon and integrates it.
//   p0 - First point
//   p1 - Second point
//   prevClipPoint - The clip point saved from the last time an edge went from above to below the horizon
//   ltcMat - The ltc lookup matrix for specular
//   diffuse - The current sum total of diffuse contribution to apply additional contribution to
//   specular - The current sum total of specular contribution to apply additional contribution to
//
// Explanation:
// When evaluating edges of a polygon there are four possible states to deal with
// 1. Both points are above the horizon.
//    - Integrate those points.
// 2. The first point is above the horizon, but the second is below.
//    - Find the point along the edge that intersects the horizon.
//    - Integrate from point 1 to the intersection point
//    - Save the intersection point for later
// 3. The first point is blow the horizon, but the second point is above.
//    - Find the point along the edge that intersects the horizon.
//    - Integate from the previous saved insection (see option 2 above) to this new insection
//    - Integrate from the new insection to the second point.
// 4. Both points are below the horizon
//    - Do nothing.

void EvaluatePolyEdge(in float3 p0, in float3 p1, inout float3 prevClipPoint, in float3x3 ltcMat, inout float diffuse, inout float specular)
{
    if (p0.z > 0.0)
    {
        if (p1.z > 0.0)
        {
            // Both above horizon
            diffuse += IntegrateEdgeDiffuse(normalize(p0), normalize(p1));
            specular += IntegrateEdge(normalize(mul(ltcMat, p0)), normalize(mul(ltcMat, p1)));
        }
        else
        {
            // Going from above to below horizon
            prevClipPoint = ClipEdge(p0, p1);
            diffuse += IntegrateEdgeDiffuse(normalize(p0), normalize(prevClipPoint));
            specular += IntegrateEdge(normalize(mul(ltcMat, p0)), normalize(mul(ltcMat, prevClipPoint)));
        }
    }
    else if (p1.z > 0.0)
    {
        // Going from below to above horizon
        float3 clipPoint = ClipEdge(p1, p0);
        diffuse += IntegrateEdgeDiffuse(normalize(prevClipPoint), normalize(clipPoint));
        diffuse += IntegrateEdgeDiffuse(normalize(clipPoint), normalize(p1));
        
        clipPoint = mul(ltcMat, clipPoint);
        specular += IntegrateEdge(normalize(mul(ltcMat, prevClipPoint)), normalize(clipPoint));
        specular += IntegrateEdge(normalize(clipPoint), normalize(mul(ltcMat, p1)));
    }
}

// Evaluates the LTC result of an arbitrary polygon lighting a surface position.
//   pos - The surface position
//   normal - The surface normal
//   dirToView - Normalized direction from the surface to the view
//   ltcMat - The LTC matrix for specular, or identity for diffuse.
//   positions - The buffer where the polygon positions are
//   startIdx - The index of the first polygon position
//   endIdx - The index of the point directly after the last polygon position
//   diffuse - The output diffuse response for the polygon light
//   specular - The output specular response for the polygon light
// The most complicated aspect of this function is clipping the polygon against the horizon of the surface point. See
// EvaluatePolyEdge() above for details on the general concept. However, this function must deal with the case of the
// first point being below the horizon. In that case, it needs to search in reverse from the end for the first point 
// above the horizon, and save the intersection point between the above and below points so it can be used in 
// EvaluatePolyEdge() later. During this search it also adjusts the end point index as necessary to avoid processing
// those points that are below the horizon.
void LtcPolygonEvaluate(
    in float3 pos, 
    in float3 normal, 
    in float3 dirToView,
    in float3x3 ltcMat,
    in StructuredBuffer<float4> positions,
    in uint startIdx,
    in uint endIdx,
    out float diffuse,
    out float specular
)
{
    if (endIdx - startIdx < 3)
    {
        return; // Must have at least 3 points to form a polygon.
    }

    // Rotate ltc matrix
    float3x3 orthonormalMat = BuildViewAlignedOrthonormalBasis(normal, dirToView);

    // Prepare initial values
    float3 p0 = mul(orthonormalMat, positions[startIdx].xyz - pos); // First point in polygon
    diffuse = 0.0;
    specular = 0.0;
    
    float3 prevClipPoint = float3(0.0, 0.0, 0.0); // Used to hold previous clip point when polygon dips below horizon.
    float3 closePoint = p0;
    
    // Handle if the first point is below the horizon.
    if (p0.z < 0.0)
    {
        float3 firstPoint = p0; // save the first point so it can be restored later.

        // Find the previous clip point so it can be used when the polygon goes above the horizon by
        // searching backwards, updating the endIdx along the way to avoid reprocessing those points later
        for ( ; endIdx > startIdx + 1; --endIdx)
        {
            float3 prevPoint = mul(orthonormalMat, positions[endIdx - 1].xyz - pos);
            if (prevPoint.z > 0.0)
            {
                prevClipPoint = ClipEdge(prevPoint, p0);
                closePoint = prevClipPoint;
                break;
            }
            p0 = prevPoint;
        }
        
        // Check if all points below horizon
        if (endIdx == startIdx + 1)
        {
            return; 
        }

        p0 = firstPoint; // Restore the original p0
    }
    
    // Evaluate all the points
    for (uint curIdx = startIdx + 1; curIdx < endIdx; ++curIdx)
    {
        float3 p1 = mul(orthonormalMat, positions[curIdx].xyz - pos); // Current point in polygon
        EvaluatePolyEdge(p0, p1, prevClipPoint, ltcMat, diffuse, specular);
        p0 = p1;
    }
    
    EvaluatePolyEdge(p0, closePoint, prevClipPoint, ltcMat, diffuse, specular);

    // Note: negated due to winding order
    diffuse = -diffuse;
    specular = -specular;
}
