/* begin-license-attribution:

This code is based in part on third-party work(s), see below for applicable
terms and attribution information.  Modifications copyright (c) Amazon.com, 
Inc. or its affiliates or licensors.

begin-original-license-text:

Copyright (c) 2017, Eric Heitz, Jonathan Dupuy, Stephen Hill and David Neubelt.
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

* If you use (or adapt) the source code in your own work, please include a 
reference to the paper:

Real-Time Polygonal-Light Shading with Linearly Transformed Cosines.
Eric Heitz, Jonathan Dupuy, Stephen Hill and David Neubelt.
ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH 2016) 35(4), 2016.
Project page: https://eheitzresearch.wordpress.com/415-2/

* Redistributions of source code must retain the above copyright notice, this
list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice,
this list of conditions and the following disclaimer in the documentation
and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

end-license-attribution */

#pragma once

#include <Atom/Features/PBR/LightingOptions.azsli>
#include <Atom/Features/PBR/Lights/LightTypesCommon.azsli>

// Generates UV coords for LTC lookup table
float2 LtcCoords(float cosTheta, float roughness)
{
    float theta = acos(cosTheta);
    float2 coords = float2(roughness, theta / (0.5 * PI));

    const float LUT_SIZE = 32.0;
    // scale and bias coordinates, for correct filtered lookup
    coords = coords * ((LUT_SIZE - 1.0) / LUT_SIZE) + (0.5 / LUT_SIZE);

    return coords;
}

// Constructs an LTC matrix from the provided texture and coordinates.
float3x3 LtcMatrix(Texture2D<float4> ltcMatrix, float2 coord)
{
    #ifdef CS_SAMPLERS
    float4 t = ltcMatrix.SampleLevel(SceneSrg::LtcSampler, coord, 0);
    #else
    float4 t = ltcMatrix.Sample(SceneSrg::LtcSampler, coord);
    #endif

    return float3x3(
        1.0, 0.0, t.w,
        0.0, t.z, 0.0,
        t.y, 0.0, t.x
    );
}

float3x3 BuildViewAlignedOrthonormalBasis(in float3 normal, in float3 dirToView)
{
    float3 tangent = normalize(dirToView - normal * dot(dirToView, normal));
    float3 bitangent = cross(normal, tangent);
    return float3x3(tangent, bitangent, normal);
}

// The following two edge integration functions are based on the work from:
// [HILL16] Real-Time Area Lighting: a Journey from Research to Production, SIGGRAPH 2016
// Ref: https://blog.selfshadow.com/publications/s2016-advances/

// Cosine integration of edge in a hemisphere. v1 and v2 should be normalized vertices above the
// xy plane in positive z space.
float IntegrateEdge(float3 v1, float3 v2)
{
    float cosTheta = dot(v1, v2);
    float absCosTheta = abs(cosTheta);

    // Cubic rational fitting of x/sin(x)
    float a = 5.42031 + (3.12829 + 0.0902326 * absCosTheta) * absCosTheta;
    float b = 3.45068 + (4.18814 + absCosTheta) * absCosTheta;
    float theta_sinTheta = a / b;

    if (cosTheta < 0.0)
    {
        theta_sinTheta = PI * rsqrt(clamp(1.0 - cosTheta * cosTheta, EPSILON, 1.0)) - theta_sinTheta;
    }

    return theta_sinTheta * cross(v1, v2).z;
}

// Cheaper version of above which is good enough for diffuse
float IntegrateEdgeDiffuse(float3 v1, float3 v2)
{
    float cosTheta = dot(v1, v2);
    float absCosTheta = abs(cosTheta);

    // Quadratic fitting of x/sin(x)
    float theta_sinTheta = 1.5708 + (-0.879406 + 0.308609 * absCosTheta) * absCosTheta;
    if (cosTheta < 0.0)
    {
        theta_sinTheta = PI * rsqrt(clamp(1.0 - cosTheta * cosTheta, EPSILON, 1.0)) - theta_sinTheta;
    }

    return theta_sinTheta * cross(v1, v2).z;
}

// Returns the unnormalized z plane intersection point between pointAboveHorizon and pointBelowHorizon.
// Once normalized, this represents a direction vector on the z plane between the directions of
// pointAboveHorizon and pointBelowHorizon.
float3 ClipEdge(in float3 pointAboveHorizon, in float3 pointBelowHorizon)
{
    return pointAboveHorizon.z * pointBelowHorizon - pointBelowHorizon.z * pointAboveHorizon;
}

// Clips a quad to above the xy plane in positive z space. Returns number of points after
// clip in vertexCount. This could have a 5 point result if only one corner is clipped.
void ClipQuadToHorizon(inout float3 p[5], out int vertexCount)
{
    // detect clipping config
    int config = 0;
    config += step(0.0, p[0].z) * 1;
    config += step(0.0, p[1].z) * 2;
    config += step(0.0, p[2].z) * 4;
    config += step(0.0, p[3].z) * 8;

    vertexCount = 0;

    switch(config)
    {
    case 0: // clip all
        break;
    case 1: // clip p[1], p[2], p[3]
        vertexCount = 3;
        p[1] = ClipEdge(p[0], p[1]);
        p[2] = ClipEdge(p[0], p[3]);
        break;
    case 2: // clip p[0], p[2], p[3]
        vertexCount = 3;
        p[0] = ClipEdge(p[1], p[0]);
        p[2] = ClipEdge(p[1], p[2]);
        break;
    case 3: // clip p[2], p[3]
        vertexCount = 4;
        p[2] = ClipEdge(p[1], p[2]);
        p[3] = ClipEdge(p[0], p[3]);
        break;
    case 4: // clip p[0], p[1], p[3]
        vertexCount = 3;
        p[0] = ClipEdge(p[2], p[3]);
        p[1] = ClipEdge(p[2], p[1]);
        break;
    case 5: // clip p[1], p[3] - impossible (opposite corners)
        break;
    case 6: // clip p[0], p[3]
        vertexCount = 4;
        p[0] = ClipEdge(p[1], p[0]);
        p[3] = ClipEdge(p[2], p[3]);
        break;
    case 7: // clip p[3]
        vertexCount = 5;
        p[4] = ClipEdge(p[0], p[3]);
        p[3] = ClipEdge(p[2], p[3]);
        break;
    case 8: // clip p[0], p[1], p[2]
        vertexCount = 3;
        p[0] = ClipEdge(p[3], p[0]);
        p[1] = ClipEdge(p[3], p[2]);
        p[2] =  p[3];
        break;
    case 9: // clip p[1], p[2]
        vertexCount = 4;
        p[1] = ClipEdge(p[0], p[1]);
        p[2] = ClipEdge(p[3], p[2]);
        break;
    case 10: // clip p[0], p[2] - impossible (opposite corners)
        break;
    case 11: // clip p[2]
        vertexCount = 5;
        p[4] = p[3];
        p[3] = ClipEdge(p[3], p[2]);
        p[2] = ClipEdge(p[1], p[2]);
        break;
    case 12: // clip p[0], p[1]
        vertexCount = 4;
        p[1] = ClipEdge(p[2], p[1]);
        p[0] = ClipEdge(p[3], p[0]);
        break;
    case 13: // clip p[1]
        vertexCount = 5;
        p[4] = p[3];
        p[3] = p[2];
        p[2] = ClipEdge(p[2], p[1]);
        p[1] = ClipEdge(p[0], p[1]);
        break;
    case 14: // clip p[0]
        vertexCount = 5;
        p[4] = ClipEdge(p[3], p[0]);
        p[0] = ClipEdge(p[1], p[0]);
        break;
    case 15: // no clipping
        vertexCount = 4;
        break;
    }
}

// Applies the LTC matrix to the clipped points of a quad.
void ApplyLtcMatrixToQuad(in float3x3 ltcMat, inout float3 p[5], in int vertexCount)
{
    // Transform points into ltc space
    p[0] = mul(ltcMat, p[0]);
    p[1] = mul(ltcMat, p[1]);
    p[2] = mul(ltcMat, p[2]);

    if (vertexCount > 3)
    {
        p[3] = mul(ltcMat, p[3]);
    }
    if (vertexCount > 4)
    {
        p[4] = mul(ltcMat, p[4]);
    }
}

// Projects the clipped points of a quad onto the sphere.
void NormalizeQuadPoints(inout float3 p[5], in int vertexCount)
{
    // project quad points onto a sphere.
    p[0] = normalize(p[0]);
    p[1] = normalize(p[1]);
    p[2] = normalize(p[2]);

    if (vertexCount > 3)
    {
        p[3] = normalize(p[3]);
    }
    if (vertexCount > 4)
    {
        p[4] = normalize(p[4]);
    }
}

// Transforms the 4 points of a quad into the hemisphere of the normal
void TransformQuadToOrthonormalBasis(in float3 normal, in float3 dirToView, in float3 p[4], out float3 tp[5])
{
    float3x3 orthoNormalBasis = BuildViewAlignedOrthonormalBasis(normal, dirToView);

    // Transform points into orthonormal space
    tp[0] = mul(orthoNormalBasis, p[0]);
    tp[1] = mul(orthoNormalBasis, p[1]);
    tp[2] = mul(orthoNormalBasis, p[2]);
    tp[3] = mul(orthoNormalBasis, p[3]);
    tp[4] = float3(0.0, 0.0, 0.0); // Extra vertex for if quad becomes a pentagon after clipping to hemisphere.
}

// Integrates the edges of a quad for lambertian diffuse contribution.
float IntegrateQuadDiffuse(in float3 v[5], in float vertexCount, in bool doubleSided)
{
    float sum = 0.0;

    NormalizeQuadPoints(v, vertexCount);

    // There must be at least 3 points so don't check for the first 2 edges.
    sum += IntegrateEdgeDiffuse(v[0], v[1]);
    sum += IntegrateEdgeDiffuse(v[1], v[2]);

    if (vertexCount > 3)
    {
        sum += IntegrateEdgeDiffuse(v[2], v[3]);
        if (vertexCount == 5)
        {
            sum += IntegrateEdgeDiffuse(v[3], v[4]);
        }
    }

    // Close the polygon
    sum += IntegrateEdgeDiffuse(v[vertexCount - 1], v[0]);

    // Note: negated due to winding order
    sum = doubleSided ? abs(sum) : max(0.0, -sum);

    return sum;
}

// Integrates the edges of a quad for specular contribution.
float IntegrateQuadSpecular(in float3 v[5], in float vertexCount, in bool doubleSided)
{
    float sum = 0.0;

    NormalizeQuadPoints(v, vertexCount);

    // There must be at least 3 points so don't check for the first 2 edges.
    sum += IntegrateEdge(v[0], v[1]);
    sum += IntegrateEdge(v[1], v[2]);

    if (vertexCount > 3)
    {
        sum += IntegrateEdge(v[2], v[3]);
        if (vertexCount == 5)
        {
            sum += IntegrateEdge(v[3], v[4]);
        }
    }

    // Close the polygon
    sum += IntegrateEdge(v[vertexCount - 1], v[0]);

    // Note: negated due to winding order
    sum = doubleSided ? abs(sum) : max(0.0, -sum);

    return sum;
}

// Transform points p into the normal's hemisphere, then clip them to the hemisphere. Returns total number of points after clipping.
int LtcQuadTransformAndClip(
    in float3 normal,
    in float3 dirToCamera,
    in float3 p[4],
    inout float3 polygon[5]
    )
{
    // Transform the points of the light into the space of the normal's hemisphere.
    TransformQuadToOrthonormalBasis(normal, dirToCamera, p, polygon);

    // Clip the light polygon to the normal hemisphere. This is done before the LTC matrix is applied to prevent
    // parts of the light below the horizon from impacting the surface. The number of points remaining after
    // the clip is returned in vertexCount. It's possible for the vertexCount of the resulting clipped quad to be
    // 0 - all points clipped (no work to do, so return)
    // 3 - 3 points clipped, leaving only a triangular corner of the quad
    // 4 - 2 or 0 points clipped, leaving a quad
    // 5 - 1 point clipped leaving a pentagon.
    int vertexCount = 0;
    ClipQuadToHorizon(polygon, vertexCount);
    return vertexCount;
}

// Evaluate the LTC specular reflectance of points in polygon. Does not scale by fresnel.
float LtcEvaluateSpecularUnscaled(
    in float2 ltcCoords,
    in Texture2D ltcMatrix,
    in float3 polygon[5],
    in int vertexCount,
    in bool doubleSided)
{
    // Look up the values for the LTC matrix based on the roughness and orientation.
    float3x3 ltcMat = LtcMatrix(ltcMatrix, ltcCoords);

    // Transform the quad based on the LTC lookup matrix
    ApplyLtcMatrixToQuad(ltcMat, polygon, vertexCount);

    // IntegrateQuadSpecular uses more accurate integration than diffuse to handle smooth surfaces correctly.
    return IntegrateQuadSpecular(polygon, vertexCount, doubleSided);
}

// Evaluate linear transform cosine lighting for a 4 point quad.
//   normal - The surface normal
//   dirToView - Normalized direction from the surface to the view
//   ltcMat - The LTC matrix for specular, or identity for diffuse.
//   p[4] - The 4 light positions relative to the surface position.
//   doubleSided - If the quad emits light from both sides
//   diffuse - The output diffuse response for the quad light
//   specular - The output specular response for the quad light
void LtcQuadEvaluate(
    in Surface surface,
    in LightingData lightingData,
    in Texture2D ltcMatrix,
    in Texture2D<float2> ltcAmpMatrix,
    in float3 p[4],
    in bool doubleSided,
    out float diffuseOut,
    out float3 specularOut)
{
    diffuseOut = 0.0f;
    specularOut = 0.0f;

    // Initialize quad with dummy point at end in case one corner is clipped (resulting in 5 sided polygon)
    float3 polygon[5];

    // Transform the points of the light into the space of the normal's hemisphere and clip to the hemisphere
    int vertexCount = LtcQuadTransformAndClip(surface.GetDefaultNormal(), lightingData.dirToCamera, p, polygon);
    if (vertexCount == 0)
    {
        diffuseOut = 0.0f;
        specularOut = float3(0.0f, 0.0f, 0.0f);
        // Entire light is below the horizon.
        return;
    }

    // IntegrateQuadDiffuse is a cheap approximation compared to specular.
    float diffuse = IntegrateQuadDiffuse(polygon, vertexCount, doubleSided);

    float2 ltcCoords = LtcCoords(dot(surface.GetDefaultNormal(), lightingData.dirToCamera), surface.roughnessLinear);
    float specular = LtcEvaluateSpecularUnscaled(ltcCoords, ltcMatrix, polygon, vertexCount, doubleSided);

    // Apply BRDF scale terms (BRDF magnitude and Schlick Fresnel)
    #ifdef CS_SAMPLERS
    float2 schlick = ltcAmpMatrix.SampleLevel(SceneSrg::LtcSampler, ltcCoords, 0).xy;
    #else
    float2 schlick = ltcAmpMatrix.Sample(SceneSrg::LtcSampler, ltcCoords).xy;
    #endif
    float3 specularRgb = specular * (schlick.x * surface.GetSpecularF0() + (1.0 - surface.GetSpecularF0()) * schlick.y);
    
#if ENABLE_CLEAR_COAT
    if(o_clearCoat_feature_enabled)
    {
        int vertexCountCc = LtcQuadTransformAndClip(surface.clearCoat.normal, lightingData.dirToCamera, p, polygon);
        if (vertexCountCc > 0)
        {
            float2 ltcCoordsCc = LtcCoords(dot(surface.clearCoat.normal, lightingData.dirToCamera), surface.clearCoat.roughness);
            float clearCoatSpecular = LtcEvaluateSpecularUnscaled(ltcCoordsCc, ltcMatrix, polygon, vertexCountCc, doubleSided);

            // Apply BRDF scale terms (BRDF magnitude and Schlick Fresnel)
            const float clearCoatSpecularF0 = 0.04;
            float2 schlickCc = ltcAmpMatrix.Sample(SceneSrg::LtcSampler, ltcCoordsCc).xy;
            float F = schlickCc.x * clearCoatSpecularF0 + (1.0 - clearCoatSpecularF0) * schlickCc.y;
            F *= surface.clearCoat.factor;

            // Attenuate diffuse and specular based on how much light the clearcoat layer reflects
            diffuse = diffuse * (1.0 - F);
            specularRgb = (specularRgb * (1.0 - F)) + (clearCoatSpecular * F);
        }
    }
#endif

    diffuseOut = diffuse;
    specularOut = specularRgb;
}

// Checks an edge against the horizon and integrates it.
//   p0 - First point
//   p1 - Second point
//   prevClipPoint - The clip point saved from the last time an edge went from above to below the horizon
//   ltcMat - The ltc lookup matrix for specular
//   diffuse - The current sum total of diffuse contribution to apply additional contribution to
//   specular - The current sum total of specular contribution to apply additional contribution to
//
// Explanation:
// When evaluating edges of a polygon there are four possible states to deal with
// 1. Both points are above the horizon.
//    - Integrate those points.
// 2. The first point is above the horizon, but the second is below.
//    - Find the point along the edge that intersects the horizon.
//    - Integrate from point 1 to the intersection point
//    - Save the intersection point for later
// 3. The first point is below the horizon, but the second point is above.
//    - Find the point along the edge that intersects the horizon.
//    - Integate from the previous saved insection (see option 2 above) to this new insection
//    - Integrate from the new insection to the second point.
// 4. Both points are below the horizon
//    - Do nothing.

void EvaluatePolyEdge(in float3 p0, in float3 p1, in float3x3 ltcMat, inout float3 prevClipPoint, inout float diffuse, inout float specular)
{
    if (p0.z > 0.0)
    {
        if (p1.z > 0.0)
        {
            // Both above horizon
            diffuse += IntegrateEdgeDiffuse(normalize(p0), normalize(p1));
            specular += IntegrateEdge(normalize(mul(ltcMat, p0)), normalize(mul(ltcMat, p1)));
        }
        else
        {
            // Going from above to below horizon
            prevClipPoint = ClipEdge(p0, p1);
            diffuse += IntegrateEdgeDiffuse(normalize(p0), normalize(prevClipPoint));
            specular += IntegrateEdge(normalize(mul(ltcMat, p0)), normalize(mul(ltcMat, prevClipPoint)));
        }
    }
    else if (p1.z > 0.0)
    {
        // Going from below to above horizon
        float3 clipPoint = ClipEdge(p1, p0);
        diffuse += IntegrateEdgeDiffuse(normalize(prevClipPoint), normalize(clipPoint));
        diffuse += IntegrateEdgeDiffuse(normalize(clipPoint), normalize(p1));
        
        clipPoint = mul(ltcMat, clipPoint);
        specular += IntegrateEdge(normalize(mul(ltcMat, prevClipPoint)), normalize(clipPoint));
        specular += IntegrateEdge(normalize(clipPoint), normalize(mul(ltcMat, p1)));
    }
}

// Same as above but only evaluates specular (used for clear coat)
void EvaluatePolyEdgeSpecularOnly(in float3 p0, in float3 p1, in float3x3 ltcMat, inout float3 prevClipPoint, inout float specular)
{
    if (p0.z > 0.0)
    {
        if (p1.z > 0.0)
        {
            // Both above horizon
            specular += IntegrateEdge(normalize(mul(ltcMat, p0)), normalize(mul(ltcMat, p1)));
        }
        else
        {
            // Going from above to below horizon
            prevClipPoint = ClipEdge(p0, p1);
            specular += IntegrateEdge(normalize(mul(ltcMat, p0)), normalize(mul(ltcMat, prevClipPoint)));
        }
    }
    else if (p1.z > 0.0)
    {
        // Going from below to above horizon
        float3 clipPoint = mul(ltcMat, ClipEdge(p1, p0));
        specular += IntegrateEdge(normalize(mul(ltcMat, prevClipPoint)), normalize(clipPoint));
        specular += IntegrateEdge(normalize(clipPoint), normalize(mul(ltcMat, p1)));
    }
}

// Evaluates the intial points to start looping through a polygon light. The first point in polygon may be below the surface
// so care must be taking to figure out which point to start with and what point to use to close the polygon.
void LtcPolygonEvaluateInitialPoints(
    in float3 surfacePosition,
    in float3x3 orthonormalMat,
    in StructuredBuffer<float4> positions,
    in uint startIdx,
    inout float3 prevClipPoint,
    inout float3 closePoint,
    inout uint endIdx,
    inout float3 p0)
{
    // Prepare initial values
    p0 = mul(orthonormalMat, positions[startIdx].xyz - surfacePosition); // First point in polygon
    
    prevClipPoint = float3(0.0, 0.0, 0.0); // Used to hold previous clip point when polygon dips below horizon.
    closePoint = p0;
    
    // Handle if the first point is below the horizon.
    if (p0.z < 0.0)
    {
        float3 firstPoint = p0; // save the first point so it can be restored later.

        // Find the previous clip point so it can be used when the polygon goes above the horizon by
        // searching backwards, updating the endIdx along the way to avoid reprocessing those points later
        for ( ; endIdx > startIdx + 1; --endIdx)
        {
            float3 prevPoint = mul(orthonormalMat, positions[endIdx - 1].xyz - surfacePosition);
            if (prevPoint.z > 0.0)
            {
                prevClipPoint = ClipEdge(prevPoint, p0);
                closePoint = prevClipPoint;
                break;
            }
            p0 = prevPoint;
        }

        p0 = firstPoint; // Restore the original p0
    }
    
}

// Evaluates the LTC result of an arbitrary polygon lighting a surface position.
//   pos - The surface position
//   normal - The surface normal
//   dirToView - Normalized direction from the surface to the view
//   ltcMat - The LTC matrix for specular, or identity for diffuse.
//   positions - The buffer where the polygon positions are
//   startIdx - The index of the first polygon position
//   endIdx - The index of the point directly after the last polygon position
//   diffuse - The output diffuse response for the polygon light
//   specular - The output specular response for the polygon light
// The most complicated aspect of this function is clipping the polygon against the horizon of the surface point. See
// EvaluatePolyEdge() above for details on the general concept. However, this function must deal with the case of the
// first point being below the horizon. In that case, it needs to search in reverse from the end for the first point 
// above the horizon, and save the intersection point between the above and below points so it can be used in 
// EvaluatePolyEdge() later. During this search it also adjusts the end point index as necessary to avoid processing
// those points that are below the horizon.
void LtcPolygonEvaluate(
    in Surface surface,
    in LightingData lightingData,
    in Texture2D ltcMatrix,
    in Texture2D<float2> ltcAmpMatrix,
    in StructuredBuffer<float4> positions,
    in uint startIdx,
    in uint endIdx,
    out float diffuseOut,
    out float3 specularRgbOut
)
{
    diffuseOut = 0.0f;
    specularRgbOut = 0.0f;

    if (endIdx - startIdx < 3)
    {
        diffuseOut = 0.0f;
        specularRgbOut = float3(0.0f, 0.0f, 0.0f);
        return; // Must have at least 3 points to form a polygon.
    }
    uint originalEndIdx = endIdx; // Original endIdx may be needed for clearcoat

    // Rotate ltc matrix
    float3x3 orthonormalMat = BuildViewAlignedOrthonormalBasis(surface.GetDefaultNormal(), lightingData.dirToCamera);

    // Evaluate the starting point (p0), previous point, and point used to close the polygon
    float3 p0, prevClipPoint, closePoint;
    LtcPolygonEvaluateInitialPoints(surface.position, orthonormalMat, positions, startIdx, prevClipPoint, closePoint, endIdx, p0);

    // Check if all points below horizon
    if (endIdx == startIdx + 1)
    {
        diffuseOut = 0.0f;
        specularRgbOut = float3(0.0f, 0.0f, 0.0f);
        return; 
    }
    
    float diffuse = 0.0;
    float specular = 0.0;

    float2 ltcCoords = LtcCoords(dot(surface.GetDefaultNormal(), lightingData.dirToCamera), surface.roughnessLinear);
    float3x3 ltcMat = LtcMatrix(ltcMatrix, ltcCoords);
    
    // Evaluate all the points
    for (uint curIdx = startIdx + 1; curIdx < endIdx; ++curIdx)
    {
        float3 p1 = mul(orthonormalMat, positions[curIdx].xyz - surface.position); // Current point in polygon
        EvaluatePolyEdge(p0, p1, ltcMat, prevClipPoint, diffuse, specular);
        p0 = p1;
    }
    
    EvaluatePolyEdge(p0, closePoint, ltcMat, prevClipPoint, diffuse, specular);

    // Note: negated due to winding order
    diffuse = -diffuse;
    specular = -specular;

    // Apply BRDF scale terms (BRDF magnitude and Schlick Fresnel)
    #ifdef CS_SAMPLERS
    float2 schlick = ltcAmpMatrix.SampleLevel(SceneSrg::LtcSampler, ltcCoords, 0).xy;
    #else
    float2 schlick = ltcAmpMatrix.Sample(SceneSrg::LtcSampler, ltcCoords).xy;
    #endif
    float3 specularRgb = specular * ((schlick.x * surface.GetSpecularF0()) + (1.0 - surface.GetSpecularF0()) * schlick.y);

#if ENABLE_CLEAR_COAT
    if(o_clearCoat_feature_enabled)
    {
        // Rotate ltc matrix
        float3x3 orthonormalMatCc = BuildViewAlignedOrthonormalBasis(surface.clearCoat.normal, lightingData.dirToCamera);

        // restore original endIdx and re-evaluate initial points with matrix based on the clearcoat normal.
        endIdx = originalEndIdx;
        LtcPolygonEvaluateInitialPoints(surface.position, orthonormalMatCc, positions, startIdx, prevClipPoint, closePoint, endIdx, p0);

        // Check if all points below horizon
        if (endIdx != startIdx + 1)
        {
            float specularCc = 0.0;

            float2 ltcCoordsCc = LtcCoords(dot(surface.clearCoat.normal, lightingData.dirToCamera), surface.clearCoat.roughness);
            float3x3 ltcMatCc = LtcMatrix(ltcMatrix, ltcCoordsCc);
            
            // Evaluate all the points
            for (uint curIdx = startIdx + 1; curIdx < endIdx; ++curIdx)
            {
                float3 p1 = mul(orthonormalMatCc, positions[curIdx].xyz - surface.position); // Current point in polygon
                EvaluatePolyEdgeSpecularOnly(p0, p1, ltcMatCc, prevClipPoint, specularCc);
                p0 = p1;
            }
            
            EvaluatePolyEdgeSpecularOnly(p0, closePoint, ltcMatCc, prevClipPoint, specularCc);

            // Note: negated due to winding order
            specularCc = -specularCc;

            // Apply BRDF scale terms (BRDF magnitude and Schlick Fresnel)
            const float clearCoatSpecularF0 = 0.04;
            float2 schlickCc = ltcAmpMatrix.Sample(SceneSrg::LtcSampler, ltcCoordsCc).xy;
            float F = clearCoatSpecularF0 * schlickCc.x + (1.0 - clearCoatSpecularF0) * schlickCc.y;
            F *= surface.clearCoat.factor;

            diffuse = diffuse * (1.0 - F);
            specularRgb = (specularRgb * (1.0 - F)) + (specularCc * F);
        }
    }
#endif

    diffuseOut = diffuse;
    specularRgbOut = specularRgb;

}
